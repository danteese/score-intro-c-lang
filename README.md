# Sistema de EvaluaciÃ³n AutomÃ¡tica de Programas C

Este sistema automatiza la evaluaciÃ³n de programas C de estudiantes, generando calificaciones detalladas, reportes PDF estÃ©ticos y anÃ¡lisis estadÃ­sticos completos.

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n General](#descripciÃ³n-general)
- [Requisitos del Sistema](#requisitos-del-sistema)
- [InstalaciÃ³n](#instalaciÃ³n)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Flujo de Trabajo](#flujo-de-trabajo)
- [Archivos Generados](#archivos-generados)
- [Uso del Sistema](#uso-del-sistema)
- [Diagrama de Secuencia](#diagrama-de-secuencia)
- [Troubleshooting](#troubleshooting)

## ğŸ¯ DescripciÃ³n General

El sistema evalÃºa automÃ¡ticamente programas C de estudiantes en cuatro categorÃ­as:
- **operaciones.c**: Operaciones bÃ¡sicas (suma, resta, multiplicaciÃ³n, divisiÃ³n, residuo)
- **resistencia.c**: CÃ¡lculo de resistencia elÃ©ctrica
- **conversionCmsMts.c**: ConversiÃ³n de centÃ­metros a metros y centÃ­metros
- **conversionSegsHMS.c**: ConversiÃ³n de segundos a horas, minutos y segundos

### CaracterÃ­sticas Principales

- âœ… **EvaluaciÃ³n automÃ¡tica** con IA (LLM)
- âœ… **Pruebas de ejecuciÃ³n** automatizadas
- âœ… **Reportes PDF estÃ©ticos** con logo institucional
- âœ… **AnÃ¡lisis estadÃ­stico** completo
- âœ… **Procesamiento en lote** de mÃºltiples estudiantes
- âœ… **GeneraciÃ³n de CSV** para anÃ¡lisis de datos

## ğŸ”§ Requisitos del Sistema

### Software Base
- **macOS** (desarrollado en macOS 24.6.0) o **Linux**
- **Bash** 4.0+
- **Python** 3.8+
- **Git**

### Herramientas de Desarrollo
- **GCC** (compilador C)
- **Ghostscript** (para manipulaciÃ³n de PDFs)
- **LaTeX** (para generaciÃ³n de PDFs)

### Python Dependencies
```bash
# Instalar en el entorno virtual
pip install pandas>=2.3.0
pip install numpy>=1.26.0
pip install python-dateutil>=2.8.2
pip install pytz>=2020.1
pip install tzdata>=2022.7
pip install six>=1.5
```

### Herramientas Externas
- **llm** (Simon Willison's LLM CLI tool)
- **Ghostscript** (`gs` command)
- **LaTeX** (para compilaciÃ³n de PDFs)

## ğŸš€ InstalaciÃ³n

### InstalaciÃ³n AutomÃ¡tica (Recomendada)
```bash
# Ejecutar script de instalaciÃ³n automÃ¡tica
./install.sh
```

### InstalaciÃ³n Manual

#### macOS
```bash
# Instalar Ghostscript
brew install ghostscript

# Instalar LaTeX (MacTeX)
brew install --cask mactex

# Instalar llm
pip install llm

# Configurar llm con tu API key
llm keys set openai

# Crear entorno virtual
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

#### Ubuntu/Debian
```bash
# Instalar Ghostscript
sudo apt-get install ghostscript

# Instalar LaTeX
sudo apt-get install texlive-full

# Instalar llm
pip install llm

# Crear entorno virtual
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

## ğŸ“ Estructura del Proyecto

```
EJ01/
â”œâ”€â”€ ğŸ“ msc25*/                    # Directorios de estudiantes
â”‚   â””â”€â”€ TAREA01/
â”‚       â”œâ”€â”€ operaciones.c
â”‚       â”œâ”€â”€ resistencia.c
â”‚       â”œâ”€â”€ conversionCmsMts.c
â”‚       â””â”€â”€ conversionSegsHMS.c
â”œâ”€â”€ ğŸ“ scores/                    # Directorio de resultados
â”‚   â”œâ”€â”€ ğŸ“„ *.json                 # Calificaciones individuales
â”‚   â”œâ”€â”€ ğŸ“„ *.csv                  # Resultados de pruebas
â”‚   â”œâ”€â”€ ğŸ“„ *.pdf                  # Reportes PDF
â”‚   â”œâ”€â”€ ğŸ“„ all_scores_merged.csv  # âš¡ GENERADO: Datos consolidados
â”‚   â”œâ”€â”€ ğŸ“„ scores_summary.csv     # âš¡ GENERADO: Resumen estadÃ­stico
â”‚   â”œâ”€â”€ ğŸ“„ student_scores.csv     # âš¡ GENERADO: Solo calificaciones
â”‚   â””â”€â”€ ğŸ“„ evaluation_results.csv # âš¡ GENERADO: Solo resultados de evaluaciÃ³n
â”œâ”€â”€ ğŸ“ public/
â”‚   â””â”€â”€ ibero.png                 # Logo institucional
â”œâ”€â”€ ğŸ“ _logs/                     # Logs del sistema
â”œâ”€â”€ ğŸ“„ all.sh                     # âš¡ SCRIPT: Procesamiento en lote
â”œâ”€â”€ ğŸ“„ general.sh                 # âš¡ SCRIPT: Proceso individual
â”œâ”€â”€ ğŸ“„ score.sh                   # âš¡ SCRIPT: EvaluaciÃ³n con IA
â”œâ”€â”€ ğŸ“„ test.sh                    # âš¡ SCRIPT: Pruebas de ejecuciÃ³n
â”œâ”€â”€ ğŸ“„ merge_pdfs.sh              # âš¡ SCRIPT: CombinaciÃ³n de PDFs
â”œâ”€â”€ ğŸ“„ generate_pdf.py            # âš¡ SCRIPT: GeneraciÃ³n de PDFs
â”œâ”€â”€ ğŸ“„ generate_test_pdf.py       # âš¡ SCRIPT: PDF de pruebas
â”œâ”€â”€ ğŸ“„ generate_scores_csv.py     # âš¡ SCRIPT: AnÃ¡lisis estadÃ­stico
â”œâ”€â”€ ğŸ“„ prompt.txt                 # Prompt para evaluaciÃ³n con IA
â””â”€â”€ ğŸ“„ README.md                  # Este archivo
```

### Archivos Generados AutomÃ¡ticamente

| Archivo | DescripciÃ³n | Generado por |
|---------|-------------|--------------|
| `scores/*.json` | Calificaciones individuales | `score.sh` |
| `scores/*.csv` | Resultados de pruebas | `test.sh` |
| `scores/calificaciones_*.pdf` | PDF de calificaciones | `generate_pdf.py` |
| `scores/testing_*.pdf` | PDF de pruebas | `generate_test_pdf.py` |
| `scores/final_report_*.pdf` | PDF combinado | `merge_pdfs.sh` |
| `scores/all_scores_merged.csv` | Datos consolidados | `generate_scores_csv.py` |
| `scores/scores_summary.csv` | Resumen estadÃ­stico | `generate_scores_csv.py` |
| `scores/student_scores.csv` | Solo calificaciones | `generate_scores_csv.py` |
| `scores/evaluation_results.csv` | Solo evaluaciones | `generate_scores_csv.py` |

## ğŸ”„ Flujo de Trabajo

### 1. EvaluaciÃ³n Individual (`general.sh`)
```bash
./general.sh msc25ahl
```

**Proceso:**
1. **EvaluaciÃ³n con IA** (`score.sh`) â†’ Genera `msc25ahl.json`
2. **Pruebas de ejecuciÃ³n** (`test.sh`) â†’ Genera `msc25ahl.csv`
3. **PDF de pruebas** (`generate_test_pdf.py`) â†’ Genera `testing_msc25ahl.pdf`
4. **PDF de calificaciones** (`generate_pdf.py`) â†’ Genera `calificaciones_msc25ahl.pdf`
5. **CombinaciÃ³n de PDFs** (`merge_pdfs.sh`) â†’ Genera `final_report_msc25ahl.pdf`

### 2. Procesamiento en Lote (`all.sh`)
```bash
./all.sh
```

**Proceso:**
- Ejecuta `general.sh` para todos los estudiantes en paralelo
- Genera todos los archivos individuales
- Al finalizar, ejecuta `generate_scores_csv.py` para anÃ¡lisis consolidado

### 3. AnÃ¡lisis EstadÃ­stico (`generate_scores_csv.py`)
```bash
source .venv/bin/activate
python3 generate_scores_csv.py
```

**Proceso:**
- Procesa todos los archivos JSON del directorio `scores/`
- Normaliza nombres de columnas (conversionSegHMS â†’ conversionSegsHMS)
- Genera 4 archivos CSV consolidados
- Crea un registro por estudiante (sin duplicados)

## ğŸš€ Uso del Sistema

### EvaluaciÃ³n de un Estudiante
```bash
# Evaluar un estudiante especÃ­fico
./general.sh msc25ahl

# Verificar archivos generados
ls -la scores/msc25ahl.*
```

### EvaluaciÃ³n de Todos los Estudiantes
```bash
# Procesar todos los estudiantes en paralelo
./all.sh

# Verificar progreso
ps aux | grep general.sh
```

### AnÃ¡lisis EstadÃ­stico
```bash
# Activar entorno virtual
source .venv/bin/activate

# Generar anÃ¡lisis consolidado
python3 generate_scores_csv.py

# Ver resultados
head scores/scores_summary.csv
```

### VerificaciÃ³n de Archivos
```bash
# Contar archivos generados
ls scores/*.pdf | wc -l
ls scores/*.json | wc -l
ls scores/*.csv | wc -l

# Verificar tamaÃ±o de archivos
du -sh scores/
```

## ğŸ“Š Diagrama de Secuencia

### Flujo Principal: EvaluaciÃ³n en Lote

```mermaid
sequenceDiagram
    participant U as Usuario
    participant A as all.sh
    participant G as general.sh
    participant S as score.sh
    participant T as test.sh
    participant GP as generate_pdf.py
    participant GT as generate_test_pdf.py
    participant M as merge_pdfs.sh
    participant CSV as generate_scores_csv.py
    participant LLM as LLM API
    participant FS as Sistema de Archivos

    U->>A: ./all.sh
    Note over A: Inicia procesamiento en paralelo
    
    A->>G: ./general.sh msc25ahl &
    A->>G: ./general.sh msc25apn &
    A->>G: ./general.sh msc25arg &
    Note over A: ... (todos los 25 estudiantes)
    
    loop Para cada estudiante (en paralelo)
        Note over G: Proceso individual por estudiante
        
        G->>S: ./score.sh msc25ahl/TAREA01
        Note over S: EvaluaciÃ³n con IA
        S->>LLM: Enviar cÃ³digo C + prompt
        LLM-->>S: Calificaciones y comentarios
        S->>FS: scores/msc25ahl.json
        S-->>G: âœ… Calificaciones generadas
        
        G->>T: ./test.sh msc25ahl/TAREA01 -o scores/msc25ahl.csv
        Note over T: Pruebas de ejecuciÃ³n
        T->>FS: Compilar programas C
        T->>FS: Ejecutar con casos de prueba
        T->>FS: scores/msc25ahl.csv
        T-->>G: âœ… Pruebas completadas
        
        G->>GT: python3 generate_test_pdf.py scores/msc25ahl.csv
        Note over GT: Generar PDF de pruebas
        GT->>FS: scores/testing_msc25ahl.pdf
        GT-->>G: âœ… PDF de pruebas generado
        
        G->>GP: python3 generate_pdf.py scores/msc25ahl.json
        Note over GP: Generar PDF de calificaciones
        GP->>FS: scores/calificaciones_msc25ahl.pdf
        GP-->>G: âœ… PDF de calificaciones generado
        
        G->>M: ./merge_pdfs.sh calificaciones + testing = final_report
        Note over M: Combinar PDFs
        M->>FS: scores/final_report_msc25ahl.pdf
        M-->>G: âœ… PDF final generado
        
        G-->>A: âœ… Estudiante procesado
    end
    
    Note over A: Esperar a que terminen todos los procesos
    
    A->>CSV: python3 generate_scores_csv.py
    Note over CSV: AnÃ¡lisis estadÃ­stico consolidado
    CSV->>FS: Procesar todos los JSON en scores/
    CSV->>FS: Normalizar nombres de columnas
    CSV->>FS: scores/all_scores_merged.csv
    CSV->>FS: scores/scores_summary.csv
    CSV->>FS: scores/student_scores.csv
    CSV->>FS: scores/evaluation_results.csv
    CSV-->>A: âœ… AnÃ¡lisis consolidado completado
    
    A-->>U: ğŸ‰ Proceso completo finalizado
    Note over U: 25 estudiantes procesados<br/>75 PDFs generados<br/>4 CSVs consolidados
```

### Flujo Detallado: EvaluaciÃ³n Individual

```mermaid
sequenceDiagram
    participant U as Usuario
    participant G as general.sh
    participant S as score.sh
    participant T as test.sh
    participant GP as generate_pdf.py
    participant GT as generate_test_pdf.py
    participant M as merge_pdfs.sh
    participant LLM as LLM API
    participant FS as Sistema de Archivos

    U->>G: ./general.sh msc25ahl
    
    Note over G: Paso 1: EvaluaciÃ³n con IA
    G->>S: ./score.sh msc25ahl/TAREA01
    S->>FS: Verificar archivos C del estudiante
    S->>LLM: Enviar cÃ³digo + prompt.txt
    LLM-->>S: JSON con calificaciones
    S->>FS: scores/msc25ahl.json
    S-->>G: âœ… Calificaciones generadas
    
    Note over G: Paso 2: Pruebas de ejecuciÃ³n
    G->>T: ./test.sh msc25ahl/TAREA01 -o scores/msc25ahl.csv
    T->>FS: Compilar operaciones.c
    T->>FS: Ejecutar con casos de prueba
    T->>FS: Compilar resistencia.c
    T->>FS: Ejecutar con casos de prueba
    T->>FS: Compilar conversionCmsMts.c
    T->>FS: Ejecutar con casos de prueba
    T->>FS: Compilar conversionSegsHMS.c
    T->>FS: Ejecutar con casos de prueba
    T->>FS: scores/msc25ahl.csv
    T-->>G: âœ… Pruebas completadas
    
    Note over G: Paso 3: PDF de pruebas
    G->>GT: python3 generate_test_pdf.py scores/msc25ahl.csv
    GT->>FS: Leer CSV de pruebas
    GT->>FS: Generar LaTeX
    GT->>FS: Compilar PDF
    GT->>FS: scores/testing_msc25ahl.pdf
    GT-->>G: âœ… PDF de pruebas generado
    
    Note over G: Paso 4: PDF de calificaciones
    G->>GP: python3 generate_pdf.py scores/msc25ahl.json
    GP->>FS: Leer JSON de calificaciones
    GP->>FS: Generar LaTeX con logo
    GP->>FS: Compilar PDF
    GP->>FS: scores/calificaciones_msc25ahl.pdf
    GP-->>G: âœ… PDF de calificaciones generado
    
    Note over G: Paso 5: Combinar PDFs
    G->>M: ./merge_pdfs.sh calificaciones + testing = final_report
    M->>FS: Leer calificaciones_msc25ahl.pdf
    M->>FS: Leer testing_msc25ahl.pdf
    M->>FS: Combinar con Ghostscript
    M->>FS: scores/final_report_msc25ahl.pdf
    M-->>G: âœ… PDF final generado
    
    G-->>U: ğŸ‰ Proceso individual completado
    Note over U: Archivos generados:<br/>â€¢ msc25ahl.json<br/>â€¢ msc25ahl.csv<br/>â€¢ calificaciones_msc25ahl.pdf<br/>â€¢ testing_msc25ahl.pdf<br/>â€¢ final_report_msc25ahl.pdf
```

### Flujo de AnÃ¡lisis EstadÃ­stico

```mermaid
sequenceDiagram
    participant U as Usuario
    participant CSV as generate_scores_csv.py
    participant FS as Sistema de Archivos
    participant PD as Pandas DataFrame

    U->>CSV: python3 generate_scores_csv.py
    
    Note over CSV: Procesar archivos JSON
    CSV->>FS: Buscar *.json en scores/
    CSV->>FS: Leer msc25ahl.json
    CSV->>FS: Leer evaluation_results_msc25ahl.json
    CSV->>FS: Leer msc25apn.json
    CSV->>FS: ... (todos los archivos)
    
    Note over CSV: Normalizar datos
    CSV->>PD: Crear DataFrame de calificaciones
    CSV->>PD: Crear DataFrame de evaluaciones
    CSV->>PD: Normalizar nombres de columnas
    CSV->>PD: conversionSegHMS â†’ conversionSegsHMS
    
    Note over CSV: Fusionar datos
    CSV->>PD: Merge por student_id
    CSV->>PD: Eliminar duplicados
    CSV->>PD: Una fila por estudiante
    
    Note over CSV: Generar archivos CSV
    CSV->>FS: scores/all_scores_merged.csv
    CSV->>FS: scores/scores_summary.csv
    CSV->>FS: scores/student_scores.csv
    CSV->>FS: scores/evaluation_results.csv
    
    CSV-->>U: âœ… AnÃ¡lisis estadÃ­stico completado
    Note over U: 4 archivos CSV generados<br/>25 estudiantes procesados<br/>Datos normalizados y consolidados
```

### Archivos Generados por Flujo

#### Flujo Individual (general.sh)
```
scores/
â”œâ”€â”€ msc25ahl.json                    # Calificaciones de IA
â”œâ”€â”€ msc25ahl.csv                     # Resultados de pruebas
â”œâ”€â”€ calificaciones_msc25ahl.pdf      # PDF de calificaciones
â”œâ”€â”€ testing_msc25ahl.pdf             # PDF de pruebas
â””â”€â”€ final_report_msc25ahl.pdf        # PDF combinado final
```

#### Flujo en Lote (all.sh)
```
scores/
â”œâ”€â”€ msc25ahl.*, msc25apn.*, ...      # Archivos individuales (25 estudiantes)
â”œâ”€â”€ all_scores_merged.csv            # âš¡ GENERADO: Datos consolidados
â”œâ”€â”€ scores_summary.csv               # âš¡ GENERADO: Resumen estadÃ­stico
â”œâ”€â”€ student_scores.csv               # âš¡ GENERADO: Solo calificaciones
â””â”€â”€ evaluation_results.csv           # âš¡ GENERADO: Solo evaluaciones
```

## ğŸ” Troubleshooting

### Problemas Comunes

#### 1. Error de LLM
```bash
# Verificar configuraciÃ³n de llm
llm keys list

# Reconfigurar si es necesario
llm keys set openai
```

#### 2. Error de Ghostscript
```bash
# Verificar instalaciÃ³n
which gs

# Instalar si no estÃ¡ disponible
brew install ghostscript  # macOS
sudo apt-get install ghostscript  # Ubuntu
```

#### 3. Error de LaTeX
```bash
# Verificar instalaciÃ³n
which pdflatex

# Instalar si no estÃ¡ disponible
brew install --cask mactex  # macOS
sudo apt-get install texlive-full  # Ubuntu
```

#### 4. Error de Pandas
```bash
# Activar entorno virtual
source .venv/bin/activate

# Instalar dependencias
pip install pandas numpy
```

#### 5. Archivos PDF corruptos
```bash
# Verificar PDFs
gs -q -dNOPAUSE -dBATCH -sDEVICE=nullpage scores/*.pdf

# Regenerar si es necesario
rm scores/*.pdf
./all.sh
```

### Logs del Sistema
```bash
# Ver logs de procesamiento
ls -la _logs/

# Ver logs en tiempo real
tail -f _logs/copy_FPROGRAOT25_TAREA01_*.csv
```

### VerificaciÃ³n de Integridad
```bash
# Verificar que todos los estudiantes fueron procesados
ls scores/*.json | wc -l
ls scores/*.pdf | wc -l

# Verificar archivos CSV consolidados
head scores/scores_summary.csv
```

## ğŸ“ˆ EstadÃ­sticas del Sistema

- **Estudiantes procesados**: 25
- **Programas evaluados por estudiante**: 4
- **Archivos JSON generados**: 25
- **Archivos PDF generados**: 75 (3 por estudiante)
- **Archivos CSV consolidados**: 4
- **Tiempo promedio por estudiante**: ~2-3 minutos
- **Tiempo total de procesamiento**: ~60-75 minutos

## ğŸ¤ Contribuciones

Para contribuir al proyecto:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crea un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ğŸ‘¥ Autores

- **Sistema de EvaluaciÃ³n**: Desarrollado para el curso de ProgramaciÃ³n I
- **Instituciones**: Universidad Iberoamericana
- **AÃ±o**: 2025

---

*Ãšltima actualizaciÃ³n: Septiembre 2025*
